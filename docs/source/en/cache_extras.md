## Overview

The cache storage abstraction now supports two caching strategies:

### 1. **K/V Pair Caching** (Traditional - Default)
- Caches the final key and value tensors after projection
- Zero recomputation cost
- Higher memory usage
- **Best for**: Standard attention, most use cases

### 2. **Hidden State Caching** (New)
- Caches pre-projection hidden states  
- Materializes to K/V pairs on-demand
- Lower memory usage, higher compute
- **Best for**: Memory-constrained scenarios


## Visual Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Attention Layer                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  â”‚   Hidden    â”‚                                                â”‚
â”‚  â”‚   States    â”‚                                                â”‚
â”‚  â”‚ [B, S, H]   â”‚                                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚         â”‚                                                       â”‚
â”‚         â”‚  Cache here? â”€â”€â”€â”€â”                                    â”‚
â”‚         â”‚                  â”‚                                    â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚         â”‚                  â”‚             â”‚                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ Q Proj  â”‚        â”‚ K Proj  â”‚   â”‚ V Proj â”‚                  â”‚
â”‚    â”‚         â”‚        â”‚         â”‚   â”‚        â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                  â”‚            â”‚                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ Queries â”‚        â”‚  Keys   â”‚   â”‚ Values â”‚                  â”‚
â”‚    â”‚[B,H,S,D]â”‚        â”‚[B,H,S,D]â”‚   â”‚[B,H,S,D]                  â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                  â”‚            â”‚                       â”‚
â”‚         â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                       â”‚                               â”‚
â”‚         â”‚              Or cache here? (traditional)             â”‚
â”‚         â”‚                       â”‚                               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                      â”‚                                          â”‚
â”‚                 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                 â”‚ Attention â”‚                                   â”‚
â”‚                 â”‚  Scores   â”‚                                   â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Storage Strategy Comparison

### Strategy 1: K/V Pair Caching (Traditional)

```
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚ Hidden State â”‚  (Not cached)
                                                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚ Project (once)
                            ---------------------------------------------------------
                            |                                                       |
                            â–¼                                                       â–¼                         
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Key Tensor  â”‚ â—„â”€â”€â”€ CACHED                             â”‚ Value Tensor â”‚ â—„â”€â”€â”€ CACHED  
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                                                       â”‚
                            â–¼                                                       â–¼
                                     (Used for attention - no recomputation)
```

**Characteristics:**
- âœ… Zero recomputation
- âŒ Higher memory (stores full K/V tensors)
- âœ… Fast access
- **Best for:** Standard self-attention

---

### Strategy 2: Hidden State Caching (New)

```
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚ Hidden State â”‚  â—„â”€â”€â”€ CACHED
                                                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚ Project (on every retrieve!)
                            ---------------------------------------------------------
                            |                                                       |
                            â–¼                                                       â–¼                         
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Key Tensor  â”‚ â—„â”€â”€â”€ (Computed on-demand)               â”‚ Value Tensor â”‚ â—„â”€â”€â”€ (Computed on-demand)  
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                                                       â”‚
                            â–¼                                                       â–¼
                                     (Used for attention - recomputation needed)

```

**Characteristics:**
- âŒ Requires recomputation (projection)
- âœ… Lower memory (stores only hidden states)
- âŒ Slower access (must materialize)
- **Best for:** memory-constrained enviroments

---

## Architecture

```
CacheStorage (Abstract Base)
â”œâ”€â”€ cache_stage: "kv_pairs" or "hidden_states"
â”œâ”€â”€ retrieve(materialize: bool)
â””â”€â”€ materialize_to_kv(**kwargs)

KVStorage (K/V Pair Caching)
â”œâ”€â”€ keys: Tensor
â””â”€â”€ values: Tensor

HiddenStateStorage (Hidden State Caching)
â”œâ”€â”€ hidden_states: Tensor
â”œâ”€â”€ k_proj: Projection layer
â”œâ”€â”€ v_proj: Projection layer
â””â”€â”€ materialize_to_kv() â†’ (keys, values)

StaticTensorStorage (Static K/V with torch.compile support)
QuantizedStorage (Quantized K/V storage)
â”œâ”€â”€ QuantoQuantizedStorage
â””â”€â”€ HQQQuantizedStorage
```


## Implementation Architecture

```
CacheStorage (Abstract Base Class)
â”œâ”€â”€ cache_stage: str
â”‚   â”œâ”€â”€ "kv_pairs" â”€â”€â–º Stores final K/V tensors
â”‚   â””â”€â”€ "hidden_states" â”€â”€â–º Stores pre-projection hidden states
â”‚
â”œâ”€â”€ initialize(key_states, value_states, **kwargs)
â”œâ”€â”€ store(key_states, value_states, **kwargs)
â”œâ”€â”€ retrieve(materialize: bool, **kwargs) â”€â”€â–º Returns (keys, values)
â”œâ”€â”€ materialize_to_kv(hidden_states, **kwargs) â”€â”€â–º Projects to K/V
â”œâ”€â”€ get_seq_length() â†’ int
â”œâ”€â”€ reset()
â”œâ”€â”€ offload()
â”œâ”€â”€ prefetch(device)
â””â”€â”€ reorder(beam_idx)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KVStorage            â”‚    â”‚  HiddenStateStorage      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cache_stage="kv_pairs" â”‚    â”‚ cache_stage="hidden_     â”‚
â”‚                        â”‚    â”‚            states"       â”‚
â”‚ keys: Tensor           â”‚    â”‚ hidden_states: Tensor    â”‚
â”‚ values: Tensor         â”‚    â”‚ k_proj: Layer/Weight     â”‚
â”‚                        â”‚    â”‚ v_proj: Layer/Weight     â”‚
â”‚ retrieve():            â”‚    â”‚                          â”‚
â”‚   return keys, values  â”‚    â”‚ retrieve(materialize):   â”‚
â”‚                        â”‚    â”‚   if materialize:        â”‚
â”‚                        â”‚    â”‚     return proj(hidden)  â”‚
â”‚                        â”‚    â”‚   else:                  â”‚
â”‚                        â”‚    â”‚     return hidden, None  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  CacheLayerMixin        â”‚
          â”‚  (Uses storage)         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚ Dynamic  â”‚             â”‚   Static   â”‚
     â”‚ Layer    â”‚             â”‚   Layer    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow Examples

### Example 1: K/V Caching (DynamicLayer)

```
Step 1: Initialize
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ layer.updateâ”‚
â”‚ (keys, vals)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KVStorage   â”‚
â”‚ .initialize()â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ keys: Tensor â”‚ Stored in memory
â”‚ values:      â”‚
â”‚   Tensor     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Retrieve
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ layer.update â”‚
â”‚ (new keys)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KVStorage   â”‚
â”‚ .retrieve()  â”‚ â”€â”€â–º Direct return (fast!)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Return cachedâ”‚
â”‚ keys, values â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example 2: Hidden State Caching

```
Step 1: Initialize
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ storage.init  â”‚
â”‚ (hidden,      â”‚
â”‚  k_proj,      â”‚
â”‚  v_proj)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HiddenState    â”‚
â”‚ Storage        â”‚
â”‚ .initialize()  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ hidden_states: â”‚ Stored
â”‚   Tensor       â”‚
â”‚ k_proj: Layer  â”‚ Reference stored
â”‚ v_proj: Layer  â”‚ Reference stored
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Retrieve (Materialize)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ storage.       â”‚
â”‚ retrieve(      â”‚
â”‚   materialize  â”‚
â”‚   =True)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HiddenState    â”‚
â”‚ Storage        â”‚
â”‚ .materialize() â”‚ â”€â”€â–º Compute projections!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ keys = k_proj  â”‚ Computed on-the-fly
â”‚   (hidden)     â”‚
â”‚ values = v_projâ”‚
â”‚   (hidden)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Return         â”‚
â”‚ (keys, values) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Memory Layout Comparison (TODO: review)

### Example: Llama-2 Style (GQA - 8 KV heads, 32 Q heads)

```
Configuration:
- Batch size: 1
- Sequence length: 1024 tokens
- Hidden dimension: 4096
- Q heads: 32, KV heads: 8
- Head dimension: 128

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ K/V Pair Caching:                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Keys:   [1, 8, 1024, 128]  = 1,048,576 values      â”‚
â”‚ Values: [1, 8, 1024, 128]  = 1,048,576 values      â”‚
â”‚ Total:  2,097,152 values Ã— 4 bytes = 8.00 MB       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hidden State Caching:                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Hidden: [1, 1024, 4096]    = 4,194,304 values      â”‚
â”‚ Total:  4,194,304 values Ã— 4 bytes = 16.00 MB      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory Ratio: 16 / 8 = 2x MORE for hidden state caching!
âŒ Not beneficial for this case
```

---

## Performance Characteristics

| Metric | KVStorage | HiddenStateStorage |
|--------|-----------|-------------------|
| Memory | Higher | Lower |
| Access Speed | Fast (O(1)) | Slower (O(n) for projection) |
| Recomputation | None | Every retrieve() call |
| Best For | Self-attention | Cross-attention, memory-constrained |
| Complexity | Simple | More complex |
| torch.compile | âœ… Supported | âœ… Supported |

---

## Use Cases

| Scenario | Recommended Storage | Reason |
|----------|-------------------|---------|
| Standard Self-Attention | `KVStorage` | Most efficient |
| Multi-Query Attention (MQA) | `KVStorage` | K/V already compressed |
| Grouped-Query Attention (GQA) | `KVStorage` | K/V already compressed |
| Cross-Attention (Encoder-Decoder) | `HiddenStateStorage` | Encoder states reused many times |
| Memory-Constrained | `HiddenStateStorage` | Trade compute for memory |
| Very Long Context | Hybrid (future) | Different strategies for different ranges |

## Future Enhancements

1. **Hybrid Caching**: Combine strategies for different context ranges
   - Recent tokens: K/V cache (fast)
   - Distant tokens: Hidden state cache (compressed)

2. **Quantized Hidden States**: Further memory compression

3. **Fused Kernels**: Optimize materialization overhead

4. **Adaptive Strategy**: Automatically choose based on:
   - Available memory
   - Reuse frequency
   - Model architecture (MQA/GQA/MHA)

## Summary

The multi-stage cache architecture provides **flexibility** to choose the right caching strategy based on:
- ğŸ“Š **Memory constraints**
- âš¡ **Compute availability**  
- ğŸ”„ **Reuse frequency**
- ğŸ—ï¸ **Model architecture** (MHA, MQA, GQA)

**Default recommendation**: Use `KVStorage` unless you have specific memory constraints or are working with cross-attention.
